Consider a 2-armed bandit situation. You are in a hurry driving a car and want to go from A to B via 2 bridges.

Optimize the exploration-exploitation strategy to minimize your time (maximize reward) during 1000 steps (episodes). Exploration: the number of random choices between the two bridges. Exploitation: the sudden or gradual switch to the bridge that you consider better.

Youâ€™ll be given the jamming probability of the bridges and also the rewards. Run a sufficient number of random tests to show the improving (average) performance throughout the 1000 learning steps.
